CODE::

// =============== decompose some sounds ===============

// let's decompose the drum loop that comes with the FluCoMa extension:
~drums = Buffer.read(s,FluidFilesPath("Nicol-LoopE-M.wav"));

// hear the original mono sound file to know what we're working with
~drums.play;

// an empty buffer for the decomposed components to be written into:
~resynth = Buffer(s);

// how many components we want FluidBufNMF to try to decompose the buffer into:
~n_components = 2;

// process it:
FluidBufNMF.processBlocking(s,~drums,resynth:~resynth,components:~n_components,resynthMode:1,action:{"done".postln;});

// once it is done, play the separated components one by one (with a second of silence in between)
(
fork{
	~n_components.do{
		arg i;
		"decomposed part #%".format(i+1).postln;
		{
			PlayBuf.ar(~n_components,~resynth,BufRateScale.ir(~resynth),doneAction:2)[i].dup;
		}.play;
		(~drums.duration + 1).wait;
	}
};
)

// ======== now let's try it with three components. =========
// make a guess as to what you think you'll hear

~n_components = 3;
// process it:
FluidBufNMF.processBlocking(s,~drums,resynth:~resynth,resynthMode:1,components:~n_components,action:{"done".postln;});

(
fork{
	~n_components.do{
		arg i;
		"decomposed part #%".format(i+1).postln;
		{
			PlayBuf.ar(~n_components,~resynth,BufRateScale.ir(~resynth),doneAction:2)[i].dup;
		}.play;
		(~drums.duration + 1).wait;
	}
};
)

// you may have guessed that it would separate out the three components into: (1) snare, (2) hihat, and (3) kick
// and it might have worked! but it may not have, and it won't provide the same result every time because it
// starts each process from a stochastic state (you can seed this state if you want...see below).

// ====== bases and activations ========

// first, let's make two new buffers called...
~bases = Buffer(s);
~activations = Buffer(s);
~n_components = 2; // return to 2 components for this example

// and we'll explicitly pass these into the process
FluidBufNMF.processBlocking(s,~drums,bases:~bases,activations:~activations,resynth:~resynth,resynthMode:1,components:~n_components,action:{"done".postln;});

// now we can plot them (because this process starts from a stochastic state, your results may vary!):
FluidWaveform(~drums,featuresBuffer:~activations,bounds:Rect(0,0,1200,300));
// the bases are a like a spectral template that FluidBufNMF has found in the source buffer
// in one you should see one spectrum that resembles a snare spectrum (the resonant tone of the snare
// in the mid range) and another that resembles the kick + hihat we heard earlier (a large peak in the very
// low register and some shimmery higher stuff)

FluidWaveform(featuresBuffer:~bases,bounds:Rect(0,0,1200,300));
// the activations are the corresponding loudness envelope of each base above. It should like an amplitude
// envelope follower of the drum hits in the corresponding bases.

// FluidBufNMF then uses the individual bases with their corresponding activations to resynthesize the sound of just
// component.
// the buffer passed to `resynth` will have one channel for each component you've requested

~resynth.numChannels
~resynth.play;

// ======== to further understand NMF's bases and activations, consider one more object: FluidNMFFilter ==========
// FluidNMFFilter will use the bases (spectral templates) of a FluidBufNMF analysis to filter (i.e., decompose) realtime audio

// for example, if we use the bases from the ~drums analysis above, it will separate the snare from the kick & hi hat like before
// this time you'll hear one in each stereo channel (again, results may vary)

(
{
	var src = PlayBuf.ar(1,~drums,BufRateScale.ir(~drums),doneAction:2);
	var sig = FluidNMFFilter.ar(src,~bases,2);
	sig;
}.play;
)

// if we play a different source through FluidNMFFilter, it will try to decompose that realtime signal according to the bases
// it is given (in our case the bases from the drum loop)
~song = Buffer.readChannel(s,FluidFilesPath("Tremblay-BeatRemember.wav"),channels:[0]);

(
{
	var src = PlayBuf.ar(1,~song,BufRateScale.ir(~song),doneAction:2);
	var sig = FluidNMFFilter.ar(src,~bases,2);
	sig;
}.play;
)

// ========= the activations could also be used as an envelope through time ===========
(
{
	var activation = PlayBuf.ar(2,~activations,BufRateScale.ir(~activations),doneAction:2);
	var sig = PinkNoise.ar(0.dbamp) * activation;
	sig;
}.play;
)

// note that the samplerate of the ~activations buffer is not a usual one...
~activations.sampleRate;
// this is because each frame in this buffer doesn't correspond to one audio sample, but instead to one
// hopSize, since these values are derived from an FFT analysis
// so it is important to use BufRateScale (as seen above) in order to make sure they play back at the
// correct rate

// if we control the amplitude of the white noise *and* send it through FluidNMFFilter, we'll get something
// somewhat resembles both the spectral template and loudness envelope of the bases of the original
// (of course it's also good to note that the combination of the *actual* bases and activations is how
// FluidBufNMF creates the channels in the resynth buffer which will sound much better than this
// filtered PinkNoise version)
(
{
	var activation = PlayBuf.ar(2,~activations,BufRateScale.ir(~activations),doneAction:2);
	var sig = PinkNoise.ar(0.dbamp);
	sig = FluidNMFFilter.ar(sig,~bases,2) * activation;
	sig;
}.play;
)

::
STRONG::Fixed Bases: The process can be trained, and the learnt bases or activations can be used as templates.::

CODE::

//set some buffers
(
b = Buffer.read(s,FluidFilesPath("Tremblay-AaS-AcousticStrums-M.wav"));

~originalNMF = Buffer.new(s);
~bases = Buffer.new(s);
~trainedBases = Buffer.new(s);
~activations = Buffer.new(s);
~final = Buffer.new(s);
~spectralshapes  = Buffer.new(s);
~stats  = Buffer.new(s);
~sortedNMF = Buffer.new(s);
)

b.play

// train using the first 2 seconds of the sound file
(
Routine {
	FluidBufNMF.processBlocking(s,b,0,44100*5,0,1, ~originalNMF, resynthMode:1, bases:~bases, components:10).wait;
	~originalNMF.query;
}.play;
)

// listen to the 10 components across the stereo image
{Splay.ar(PlayBuf.ar(10, ~originalNMF))}.play

// plot the bases
~bases.query
~bases.plot

// find the component that has the picking sound by checking the median spectral centroid
(
FluidBufSpectralShape.process(s, ~originalNMF, features: ~spectralshapes, action:{
	|shapes|FluidBufStats.process(s,shapes,stats:~stats, action:{
		|stats|stats.getn(0, (stats.numChannels * stats.numFrames) ,{
			|x| ~centroids = x.select({
				|item, index| (index.mod(7) == 0) && (index.div(70) == 5);
			})
		})
	})
});
)

//what is happening there? We run the spectralshapes on the buffer of 10 components from the nmf. See the structure of that buffer:
~originalNMF.query
//10 channel are therefore giving 70 channels: the 7 shapes of component0, then 7 shapes of compoenent1, etc
~spectralshapes.query
// we then run the bufstats on them. Each channel, which had a time series (an envelope) of each descriptor, is reduced to 7 frames
~stats.query
// we then need to retrieve the values that are where we want: the first of every 7 for the centroid, and the 6th frame of them as we want the median. Because we retrieve the values in an interleave format, the select function gets a bit tricky but we get the following values:
~centroids.postln

// we then copy the basis with the highest median centroid to a channel, and all the other bases to the other channel, of a 2-channel bases for decomposition
(
z = (0..9);
[z.removeAt(~centroids.maxIndex)].do{|chan|FluidBufCompose.process(s, ~bases, startChan: chan, numChans: 1, destination: ~trainedBases, destGain:1)};
z.postln;
z.do({|chan| FluidBufCompose.process(s, ~bases, startChan:chan, numChans: 1, destStartChan: 1, destination: ~trainedBases, destGain:1)});
)

~trainedBases.plot

//process the whole file, splitting it with the 2 trained bases
(
Routine{
	FluidBufNMF.process(s, b, resynth: ~sortedNMF, resynthMode:1, bases: ~trainedBases, basesMode: 2, components:2).wait;
	~originalNMF.query;
}.play;
)

// play the result: pick on the left, sustain on the right!
{PlayBuf.ar(2,~sortedNMF)}.play

// it even null-sums
{(PlayBuf.ar(2,~sortedNMF,doneAction:2).sum)-(PlayBuf.ar(1,b,doneAction:2))}.play
::

STRONG::Updating Bases: The process can update bases provided as seed.::

CODE::
(
// create buffers
b = Buffer.alloc(s,44100);
c = Buffer.alloc(s, 44100);
d = Buffer.new(s);
e = Buffer.alloc(s,513,3);
f = Buffer.new(s);
g = Buffer.new(s);
)

(
// fill them with 2 clearly segregated sine waves and composite a buffer where they are consecutive
Routine {
	b.sine2([500],[1], false, false);
	c.sine2([5000],[1],false, false);
	s.sync;
	FluidBufCompose.process(s,b, destination:d);
	FluidBufCompose.process(s,c, destStartFrame:44100, destination:d, destGain:1);
	s.sync;
	d.query;
}.play;
)

// check
d.plot
d.play //////(beware !!!! loud!!!)

(
//make a seeding basis of 3 components:
var highpass, lowpass, direct;
highpass = Array.fill(513,{|i| (i < 50).asInteger});
lowpass = 1 - highpass;
direct = Array.fill(513,0.1);
e.setn(0,[highpass, lowpass, direct].flop.flat);
)

//check the basis: a steep lowpass, a steep highpass, and a small DC
e.plot
e.query

(
// use the seeding basis, without updating
Routine {
	FluidBufNMF.process(s, d, resynth:f, resynthMode:1, bases: e, basesMode: 2, activations:g, components:3).wait;
	e.query;
	f.query;
	g.query;
}.play
)

// look at the resynthesised separated signal
f.plot;

// look at the bases that have not changed
e.plot;

// look at the activations
g.plot;

(
// use the seeding bases, with updating this time
Routine {
	FluidBufNMF.process(s, d, resynth:f, resynthMode:1, bases: e, basesMode: 1, activations:g, components:3).wait;
	e.query;
	f.query;
	g.query;
}.play
)

// look at the resynthesised separated signal
f.plot;

// look at the bases that have now updated in place (with the 3rd channel being more focused
e.plot;

// look at the activations (sharper 3rd component at transitions)
g.plot;
::
